{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "nltk.download()\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DataSetMaster.csv\") # reading the dataset\n",
    "dfo = df # making a copy of the dataset\n",
    "df, dfo = train_test_split(df, test_size = 0.3)# splitting into test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>I have one female cat that weighs under 10 pou...</td>\n",
       "      <td>Pet Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>Our lab carries around sticks, rocks, you name...</td>\n",
       "      <td>Pet Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12184</th>\n",
       "      <td>When I first got this movie, I was expecting a...</td>\n",
       "      <td>CD &amp; Vinyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>Got this game for my birthday last year. I lov...</td>\n",
       "      <td>ToysAndGames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20125</th>\n",
       "      <td>I don't know, but from now on, I won't. It is ...</td>\n",
       "      <td>HomeAndKitchen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review           Class\n",
       "5933   I have one female cat that weighs under 10 pou...    Pet Supplies\n",
       "5764   Our lab carries around sticks, rocks, you name...    Pet Supplies\n",
       "12184  When I first got this movie, I was expecting a...     CD & Vinyl \n",
       "9880   Got this game for my birthday last year. I lov...    ToysAndGames\n",
       "20125  I don't know, but from now on, I won't. It is ...  HomeAndKitchen"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'more', 'after', 'll', 'haven', 'on', 'about', 'why', 'an', 'with', 'where', 'won', 'who', 'we', 'a', 'its', 'wasn', 'o', 'but', 'y', 'her', 'can', 'be', 'very', 'should', 'whom', 're', 'while', 'yourself', 'have', 'off', 'against', 'shan', 'are', 'does', 'those', 'just', 'as', 'each', 'such', 'not', 'wouldn', 've', 'once', 'has', 'of', 'too', 'their', 'theirs', 'mightn', 'most', 'me', 'both', 'over', 't', 'isn', 'am', 'to', 'himself', 'ain', 'out', 'were', 'they', 'them', 'here', 'when', 'up', 'between', 'you', 'same', 'at', 'ourselves', 'd', 'nor', 'she', 'then', 'him', 'don', 'some', 'i', 'will', 'above', 'what', 'there', 'for', 'into', 'below', 'no', 'before', 'under', 'own', 'than', 'other', 'down', 'themselves', 'needn', 'didn', 'doing', 'his', 'and', 'any', 'couldn', 'the', 'until', 'was', 'had', 'that', 'this', 'shouldn', 'our', 'yourselves', 'do', 'hasn', 'having', 'again', 'weren', 'from', 'herself', 'how', 'further', 'all', 'is', 'm', 'did', 'or', 'few', 'if', 'myself', 'my', 'by', 'because', 'which', 'so', 'being', 'during', 'ours', 'only', 'hadn', 'aren', 'now', 'through', 'it', 's', 'he', 'hers', 'doesn', 'itself', 'ma', 'been', 'these', 'in', 'your', 'mustn', 'yours'}\n"
     ]
    }
   ],
   "source": [
    "stoplist = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stoplist.update(['a',\n",
    "'able',\n",
    "'about',\n",
    "'above',\n",
    "'abst',\n",
    "'accordance',\n",
    "'according',\n",
    "'accordingly',\n",
    "'across',\n",
    "'act',\n",
    "'actually',\n",
    "'added',\n",
    "'adj',\n",
    "'affected',\n",
    "'affecting',\n",
    "'affects',\n",
    "'after',\n",
    "'afterwards',\n",
    "'again',\n",
    "'against',\n",
    "'ah',\n",
    "'all',\n",
    "'almost',\n",
    "'alone',\n",
    "'along',\n",
    "'already',\n",
    "'also',\n",
    "'although',\n",
    "'always',\n",
    "'am',\n",
    "'among',\n",
    "'amongst',\n",
    "'an',\n",
    "'and',\n",
    "'announce',\n",
    "'another',\n",
    "'any',\n",
    "'anybody',\n",
    "'anyhow',\n",
    "'anymore',\n",
    "'anyone',\n",
    "'anything',\n",
    "'anyway',\n",
    "'anyways',\n",
    "'anywhere',\n",
    "'apparently',\n",
    "'approximately',\n",
    "'are',\n",
    "'aren',\n",
    "'arent',\n",
    "'arise',\n",
    "'around',\n",
    "'as',\n",
    "'aside',\n",
    "'ask',\n",
    "'asking',\n",
    "'at',\n",
    "'auth',\n",
    "'available',\n",
    "'away',\n",
    "'awfully',\n",
    "'b',\n",
    "'back',\n",
    "'be',\n",
    "'became',\n",
    "'because',\n",
    "'become',\n",
    "'becomes',\n",
    "'becoming',\n",
    "'been',\n",
    "'before',\n",
    "'beforehand',\n",
    "'begin',\n",
    "'beginning',\n",
    "'beginnings',\n",
    "'begins',\n",
    "'behind',\n",
    "'being',\n",
    "'believe',\n",
    "'below',\n",
    "'beside',\n",
    "'besides',\n",
    "'between',\n",
    "'beyond',\n",
    "'biol',\n",
    "'both',\n",
    "'brief',\n",
    "'briefly',\n",
    "'but',\n",
    "'by',\n",
    "'c',\n",
    "'ca',\n",
    "'came',\n",
    "'can',\n",
    "'cannot',\n",
    "'cant',\n",
    "'cause',\n",
    "'causes',\n",
    "'certain',\n",
    "'certainly',\n",
    "'co',\n",
    "'com',\n",
    "'come',\n",
    "'comes',\n",
    "'contain',\n",
    "'containing',\n",
    "'contains',\n",
    "'could',\n",
    "'couldnt',\n",
    "'d',\n",
    "'date',\n",
    "'did',\n",
    "'didnt',\n",
    "'different',\n",
    "'do',\n",
    "'does',\n",
    "'doesnt',\n",
    "'doing',\n",
    "'done',\n",
    "'dont',\n",
    "'down',\n",
    "'downwards',\n",
    "'due',\n",
    "'during',\n",
    "'e',\n",
    "'each',\n",
    "'ed',\n",
    "'edu',\n",
    "'effect',\n",
    "'eg',\n",
    "'eight',\n",
    "'eighty',\n",
    "'either',\n",
    "'else',\n",
    "'elsewhere',\n",
    "'end',\n",
    "'ending',\n",
    "'enough',\n",
    "'especially',\n",
    "'et',\n",
    "'et-al',\n",
    "'etc',\n",
    "'even',\n",
    "'ever',\n",
    "'every',\n",
    "'everybody',\n",
    "'everyone',\n",
    "'everything',\n",
    "'everywhere',\n",
    "'ex',\n",
    "'except',\n",
    "'f',\n",
    "'far',\n",
    "'few',\n",
    "'ff',\n",
    "'fifth',\n",
    "'first',\n",
    "'five',\n",
    "'fix',\n",
    "'followed',\n",
    "'following',\n",
    "'follows',\n",
    "'for',\n",
    "'former',\n",
    "'formerly',\n",
    "'forth',\n",
    "'found',\n",
    "'four',\n",
    "'from',\n",
    "'further',\n",
    "'furthermore',\n",
    "'g',\n",
    "'gave',\n",
    "'get',\n",
    "'gets',\n",
    "'getting',\n",
    "'give',\n",
    "'given',\n",
    "'gives',\n",
    "'giving',\n",
    "'go',\n",
    "'goes',\n",
    "'gone',\n",
    "'got',\n",
    "'gotten',\n",
    "'h',\n",
    "'had',\n",
    "'happens',\n",
    "'hardly',\n",
    "'has',\n",
    "'hasnt',\n",
    "'have',\n",
    "'havent',\n",
    "'having',\n",
    "'he',\n",
    "'hed',\n",
    "'hence',\n",
    "'her',\n",
    "'here',\n",
    "'hereafter',\n",
    "'hereby',\n",
    "'herein',\n",
    "'heres',\n",
    "'hereupon',\n",
    "'hers',\n",
    "'herself',\n",
    "'hes',\n",
    "'hi',\n",
    "'hid',\n",
    "'him',\n",
    "'himself',\n",
    "'his',\n",
    "'hither',\n",
    "'home',\n",
    "'how',\n",
    "'howbeit',\n",
    "'however',\n",
    "'hundred',\n",
    "'i',\n",
    "'id',\n",
    "'ie',\n",
    "'if',\n",
    "'ill',\n",
    "'im',\n",
    "'immediate',\n",
    "'immediately',\n",
    "'importance',\n",
    "'important',\n",
    "'in',\n",
    "'inc',\n",
    "'indeed',\n",
    "'index',\n",
    "'information',\n",
    "'instead',\n",
    "'into',\n",
    "'invention',\n",
    "'inward',\n",
    "'is',\n",
    "'isnt',\n",
    "'it',\n",
    "'itd',\n",
    "'itll',\n",
    "'its',\n",
    "'itself',\n",
    "'ive',\n",
    "'j',\n",
    "'just',\n",
    "'k',\n",
    "'keep',\n",
    "'keeps',\n",
    "'kept',\n",
    "'kg',\n",
    "'km',\n",
    "'know',\n",
    "'known',\n",
    "'knows',\n",
    "'l',\n",
    "'largely',\n",
    "'last',\n",
    "'lately',\n",
    "'later',\n",
    "'latter',\n",
    "'latterly',\n",
    "'least',\n",
    "'less',\n",
    "'lest',\n",
    "'let',\n",
    "'lets',\n",
    "'like',\n",
    "'liked',\n",
    "'likely',\n",
    "'line',\n",
    "'little',\n",
    "'ll',\n",
    "'look',\n",
    "'looking',\n",
    "'looks',\n",
    "'ltd',\n",
    "'m',\n",
    "'made',\n",
    "'mainly',\n",
    "'make',\n",
    "'makes',\n",
    "'many',\n",
    "'may',\n",
    "'maybe',\n",
    "'me',\n",
    "'mean',\n",
    "'means',\n",
    "'meantime',\n",
    "'meanwhile',\n",
    "'merely',\n",
    "'mg',\n",
    "'might',\n",
    "'million',\n",
    "'miss',\n",
    "'ml',\n",
    "'more',\n",
    "'moreover',\n",
    "'most',\n",
    "'mostly',\n",
    "'mr',\n",
    "'mrs',\n",
    "'much',\n",
    "'mug',\n",
    "'must',\n",
    "'my',\n",
    "'myself',\n",
    "'n',\n",
    "'na',\n",
    "'name',\n",
    "'namely',\n",
    "'nay',\n",
    "'nd',\n",
    "'near',\n",
    "'nearly',\n",
    "'necessarily',\n",
    "'necessary',\n",
    "'need',\n",
    "'needs',\n",
    "'neither',\n",
    "'never',\n",
    "'nevertheless',\n",
    "'new',\n",
    "'next',\n",
    "'nine',\n",
    "'ninety',\n",
    "'no',\n",
    "'nobody',\n",
    "'non',\n",
    "'none',\n",
    "'nonetheless',\n",
    "'noone',\n",
    "'nor',\n",
    "'normally',\n",
    "'nos',\n",
    "'not',\n",
    "'noted',\n",
    "'nothing',\n",
    "'now',\n",
    "'nowhere',\n",
    "'o',\n",
    "'obtain',\n",
    "'obtained',\n",
    "'obviously',\n",
    "'of',\n",
    "'off',\n",
    "'often',\n",
    "'oh',\n",
    "'ok',\n",
    "'okay',\n",
    "'old',\n",
    "'omitted',\n",
    "'on',\n",
    "'once',\n",
    "'one',\n",
    "'ones',\n",
    "'only',\n",
    "'onto',\n",
    "'or',\n",
    "'ord',\n",
    "'other',\n",
    "'others',\n",
    "'otherwise',\n",
    "'ought',\n",
    "'our',\n",
    "'ours',\n",
    "'ourselves',\n",
    "'out',\n",
    "'outside',\n",
    "'over',\n",
    "'overall',\n",
    "'owing',\n",
    "'own',\n",
    "'p',\n",
    "'page',\n",
    "'pages',\n",
    "'part',\n",
    "'particular',\n",
    "'particularly',\n",
    "'past',\n",
    "'per',\n",
    "'perhaps',\n",
    "'placed',\n",
    "'please',\n",
    "'plus',\n",
    "'poorly',\n",
    "'possible',\n",
    "'possibly',\n",
    "'potentially',\n",
    "'pp',\n",
    "'predominantly',\n",
    "'present',\n",
    "'previously',\n",
    "'primarily',\n",
    "'probably',\n",
    "'promptly',\n",
    "'proud',\n",
    "'provides',\n",
    "'put',\n",
    "'q',\n",
    "'que',\n",
    "'quickly',\n",
    "'quite',\n",
    "'qv',\n",
    "'r',\n",
    "'ran',\n",
    "'rather',\n",
    "'rd',\n",
    "'re',\n",
    "'readily',\n",
    "'really',\n",
    "'recent',\n",
    "'recently',\n",
    "'ref',\n",
    "'refs',\n",
    "'regarding',\n",
    "'regardless',\n",
    "'regards',\n",
    "'related',\n",
    "'relatively',\n",
    "'research',\n",
    "'respectively',\n",
    "'resulted',\n",
    "'resulting',\n",
    "'results',\n",
    "'right',\n",
    "'run',\n",
    "'s',\n",
    "'said',\n",
    "'same',\n",
    "'saw',\n",
    "'say',\n",
    "'saying',\n",
    "'says',\n",
    "'sec',\n",
    "'section',\n",
    "'see',\n",
    "'seeing',\n",
    "'seem',\n",
    "'seemed',\n",
    "'seeming',\n",
    "'seems',\n",
    "'seen',\n",
    "'self',\n",
    "'selves',\n",
    "'sent',\n",
    "'seven',\n",
    "'several',\n",
    "'shall',\n",
    "'she',\n",
    "'shed',\n",
    "'shell',\n",
    "'shes',\n",
    "'should',\n",
    "'shouldnt',\n",
    "'show',\n",
    "'showed',\n",
    "'shown',\n",
    "'showns',\n",
    "'shows',\n",
    "'significant',\n",
    "'significantly',\n",
    "'similar',\n",
    "'similarly',\n",
    "'since',\n",
    "'six',\n",
    "'slightly',\n",
    "'so',\n",
    "'some',\n",
    "'somebody',\n",
    "'somehow',\n",
    "'someone',\n",
    "'somethan',\n",
    "'something',\n",
    "'sometime',\n",
    "'sometimes',\n",
    "'somewhat',\n",
    "'somewhere',\n",
    "'soon',\n",
    "'sorry',\n",
    "'specifically',\n",
    "'specified',\n",
    "'specify',\n",
    "'specifying',\n",
    "'still',\n",
    "'stop',\n",
    "'strongly',\n",
    "'sub',\n",
    "'substantially',\n",
    "'successfully',\n",
    "'such',\n",
    "'sufficiently',\n",
    "'suggest',\n",
    "'sup',\n",
    "'sure',\n",
    "'t',\n",
    "'take',\n",
    "'taken',\n",
    "'taking',\n",
    "'tell',\n",
    "'tends',\n",
    "'th',\n",
    "'than',\n",
    "'thank',\n",
    "'thanks',\n",
    "'thanx',\n",
    "'that',\n",
    "'thatll',\n",
    "'thats',\n",
    "'thatve',\n",
    "'the',\n",
    "'their',\n",
    "'theirs',\n",
    "'them',\n",
    "'themselves',\n",
    "'then',\n",
    "'thence',\n",
    "'there',\n",
    "'thereafter',\n",
    "'thereby',\n",
    "'thered',\n",
    "'therefore',\n",
    "'therein',\n",
    "'therell',\n",
    "'thereof',\n",
    "'therere',\n",
    "'theres',\n",
    "'thereto',\n",
    "'thereupon',\n",
    "'thereve',\n",
    "'these',\n",
    "'they',\n",
    "'theyd',\n",
    "'theyll',\n",
    "'theyre',\n",
    "'theyve',\n",
    "'think',\n",
    "'this',\n",
    "'those',\n",
    "'thou',\n",
    "'though',\n",
    "'thoughh',\n",
    "'thousand',\n",
    "'throug',\n",
    "'through',\n",
    "'throughout',\n",
    "'thru',\n",
    "'thus',\n",
    "'til',\n",
    "'tip',\n",
    "'to',\n",
    "'together',\n",
    "'too',\n",
    "'took',\n",
    "'toward',\n",
    "'towards',\n",
    "'tried',\n",
    "'tries',\n",
    "'truly',\n",
    "'try',\n",
    "'trying',\n",
    "'ts',\n",
    "'twice',\n",
    "'two',\n",
    "'u',\n",
    "'un',\n",
    "'under',\n",
    "'unfortunately',\n",
    "'unless',\n",
    "'unlike',\n",
    "'unlikely',\n",
    "'until',\n",
    "'unto',\n",
    "'up',\n",
    "'upon',\n",
    "'ups',\n",
    "'us',\n",
    "'use',\n",
    "'used',\n",
    "'useful',\n",
    "'usefully',\n",
    "'usefulness',\n",
    "'uses',\n",
    "'using',\n",
    "'usually',\n",
    "'v',\n",
    "'value',\n",
    "'various',\n",
    "'ve',\n",
    "'very',\n",
    "'via',\n",
    "'viz',\n",
    "'vol',\n",
    "'vols',\n",
    "'vs',\n",
    "'w',\n",
    "'want',\n",
    "'wants',\n",
    "'was',\n",
    "'wasnt',\n",
    "'way',\n",
    "'we',\n",
    "'wed',\n",
    "'welcome',\n",
    "'well',\n",
    "'went',\n",
    "'were',\n",
    "'werent',\n",
    "'weve',\n",
    "'what',\n",
    "'whatever',\n",
    "'whatll',\n",
    "'whats',\n",
    "'when',\n",
    "'whence',\n",
    "'whenever',\n",
    "'where',\n",
    "'whereafter',\n",
    "'whereas',\n",
    "'whereby',\n",
    "'wherein',\n",
    "'wheres',\n",
    "'whereupon',\n",
    "'wherever',\n",
    "'whether',\n",
    "'which',\n",
    "'while',\n",
    "'whim',\n",
    "'whither',\n",
    "'who',\n",
    "'whod',\n",
    "'whoever',\n",
    "'whole',\n",
    "'wholl',\n",
    "'whom',\n",
    "'whomever',\n",
    "'whos',\n",
    "'whose',\n",
    "'why',\n",
    "'widely',\n",
    "'willing',\n",
    "'wish',\n",
    "'with',\n",
    "'within',\n",
    "'without',\n",
    "'wont',\n",
    "'words',\n",
    "'world',\n",
    "'would',\n",
    "'wouldnt',\n",
    "'www',\n",
    "'x',\n",
    "'y',\n",
    "'yes',\n",
    "'yet',\n",
    "'you',\n",
    "'youd',\n",
    "'youll',\n",
    "'your',\n",
    "'youre',\n",
    "'yours',\n",
    "'yourself',\n",
    "'yourselves',\n",
    "'youve',\n",
    "'z',\n",
    "'zero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abst',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'act',\n",
       " 'actually',\n",
       " 'added',\n",
       " 'adj',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ah',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'announce',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apparently',\n",
       " 'approximately',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'arent',\n",
       " 'arise',\n",
       " 'around',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'at',\n",
       " 'auth',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awfully',\n",
       " 'b',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'beginnings',\n",
       " 'begins',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'biol',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'briefly',\n",
       " 'but',\n",
       " 'by',\n",
       " 'c',\n",
       " 'ca',\n",
       " 'came',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'co',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'couldnt',\n",
       " 'd',\n",
       " 'date',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'different',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'due',\n",
       " 'during',\n",
       " 'e',\n",
       " 'each',\n",
       " 'ed',\n",
       " 'edu',\n",
       " 'effect',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'eighty',\n",
       " 'either',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'enough',\n",
       " 'especially',\n",
       " 'et',\n",
       " 'et-al',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'except',\n",
       " 'f',\n",
       " 'far',\n",
       " 'few',\n",
       " 'ff',\n",
       " 'fifth',\n",
       " 'first',\n",
       " 'five',\n",
       " 'fix',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forth',\n",
       " 'found',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'g',\n",
       " 'gave',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'give',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'h',\n",
       " 'had',\n",
       " 'hadn',\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'has',\n",
       " 'hasn',\n",
       " 'hasnt',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'havent',\n",
       " 'having',\n",
       " 'he',\n",
       " 'hed',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'heres',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'hes',\n",
       " 'hi',\n",
       " 'hid',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'home',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'id',\n",
       " 'ie',\n",
       " 'if',\n",
       " 'ill',\n",
       " 'im',\n",
       " 'immediate',\n",
       " 'immediately',\n",
       " 'importance',\n",
       " 'important',\n",
       " 'in',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'index',\n",
       " 'information',\n",
       " 'instead',\n",
       " 'into',\n",
       " 'invention',\n",
       " 'inward',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'isnt',\n",
       " 'it',\n",
       " 'itd',\n",
       " 'itll',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'ive',\n",
       " 'j',\n",
       " 'just',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'kg',\n",
       " 'km',\n",
       " 'know',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'l',\n",
       " 'largely',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " 'lets',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'line',\n",
       " 'little',\n",
       " 'll',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'ltd',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'made',\n",
       " 'mainly',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'means',\n",
       " 'meantime',\n",
       " 'meanwhile',\n",
       " 'merely',\n",
       " 'mg',\n",
       " 'might',\n",
       " 'mightn',\n",
       " 'million',\n",
       " 'miss',\n",
       " 'ml',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'mr',\n",
       " 'mrs',\n",
       " 'much',\n",
       " 'mug',\n",
       " 'must',\n",
       " 'mustn',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'n',\n",
       " 'na',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nay',\n",
       " 'nd',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessarily',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needn',\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'ninety',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'nonetheless',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'nos',\n",
       " 'not',\n",
       " 'noted',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'o',\n",
       " 'obtain',\n",
       " 'obtained',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'omitted',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'ord',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'owing',\n",
       " 'own',\n",
       " 'p',\n",
       " 'page',\n",
       " 'pages',\n",
       " 'part',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'past',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'poorly',\n",
       " 'possible',\n",
       " 'possibly',\n",
       " 'potentially',\n",
       " 'pp',\n",
       " 'predominantly',\n",
       " 'present',\n",
       " 'previously',\n",
       " 'primarily',\n",
       " 'probably',\n",
       " 'promptly',\n",
       " 'proud',\n",
       " 'provides',\n",
       " 'put',\n",
       " 'q',\n",
       " 'que',\n",
       " 'quickly',\n",
       " 'quite',\n",
       " 'qv',\n",
       " 'r',\n",
       " 'ran',\n",
       " 'rather',\n",
       " 'rd',\n",
       " 're',\n",
       " 'readily',\n",
       " 'really',\n",
       " 'recent',\n",
       " 'recently',\n",
       " 'ref',\n",
       " 'refs',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'related',\n",
       " 'relatively',\n",
       " 'research',\n",
       " 'respectively',\n",
       " 'resulted',\n",
       " 'resulting',\n",
       " 'results',\n",
       " 'right',\n",
       " 'run',\n",
       " 's',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'sec',\n",
       " 'section',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sent',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " 'shan',\n",
       " 'she',\n",
       " 'shed',\n",
       " 'shell',\n",
       " 'shes',\n",
       " 'should',\n",
       " 'shouldn',\n",
       " 'shouldnt',\n",
       " 'show',\n",
       " 'showed',\n",
       " 'shown',\n",
       " 'showns',\n",
       " 'shows',\n",
       " 'significant',\n",
       " 'significantly',\n",
       " 'similar',\n",
       " 'similarly',\n",
       " 'since',\n",
       " 'six',\n",
       " 'slightly',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'somethan',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'specifically',\n",
       " 'specified',\n",
       " 'specify',\n",
       " 'specifying',\n",
       " 'still',\n",
       " 'stop',\n",
       " 'strongly',\n",
       " 'sub',\n",
       " 'substantially',\n",
       " 'successfully',\n",
       " 'such',\n",
       " 'sufficiently',\n",
       " 'suggest',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 't',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'taking',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'th',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " 'thatll',\n",
       " 'thats',\n",
       " 'thatve',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'thered',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'therell',\n",
       " 'thereof',\n",
       " 'therere',\n",
       " 'theres',\n",
       " 'thereto',\n",
       " 'thereupon',\n",
       " 'thereve',\n",
       " 'these',\n",
       " 'they',\n",
       " 'theyd',\n",
       " 'theyll',\n",
       " 'theyre',\n",
       " 'theyve',\n",
       " 'think',\n",
       " 'this',\n",
       " 'those',\n",
       " 'thou',\n",
       " 'though',\n",
       " 'thoughh',\n",
       " 'thousand',\n",
       " 'throug',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'til',\n",
       " 'tip',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'ts',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'u',\n",
       " 'un',\n",
       " 'under',\n",
       " 'unfortunately',\n",
       " 'unless',\n",
       " 'unlike',\n",
       " 'unlikely',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'ups',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'usefully',\n",
       " 'usefulness',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'v',\n",
       " 'value',\n",
       " 'various',\n",
       " 've',\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vol',\n",
       " 'vols',\n",
       " 'vs',\n",
       " 'w',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'wasnt',\n",
       " 'way',\n",
       " 'we',\n",
       " 'wed',\n",
       " 'welcome',\n",
       " 'well',\n",
       " 'went',\n",
       " 'were',\n",
       " 'weren',\n",
       " 'werent',\n",
       " 'weve',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'whatll',\n",
       " 'whats',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'wheres',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whim',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whod',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'wholl',\n",
       " 'whom',\n",
       " 'whomever',\n",
       " 'whos',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'widely',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'won',\n",
       " 'wont',\n",
       " 'words',\n",
       " 'world',\n",
       " 'would',\n",
       " 'wouldn',\n",
       " 'wouldnt',\n",
       " 'www',\n",
       " 'x',\n",
       " 'y',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'youd',\n",
       " 'youll',\n",
       " 'your',\n",
       " 'youre',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'youve',\n",
       " 'z',\n",
       " 'zero'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = []\n",
    "for review in df.values:\n",
    "        # Remove punctuations\n",
    "        \n",
    "        review[0] = re.sub(r'[^a-zA-Z]', ' ', review[0])\n",
    "        # To lowercase\n",
    "        review[0] = review[0].lower()\n",
    "        # Remove stop words\n",
    "        texts = [word for word in review[0].lower().split() if word not in stoplist]\n",
    "        try:\n",
    "            #review[0].append(' '.join(texts))\n",
    "            review[0] = ' '.join(texts)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'secret nimh told contained story epic loose ends left tantalize imagination ii picks threads tale weaves equally stirring saga adding shocking plot twists rousing musical numbers good measure tradition favorite plot devices learn young timothy brisby destiny fulfill chosen journeys rats thorn valley film wondered sort utopian society rats create liberated hide farmhouse rosebush nimh delivers greater spectacle conceived wondrous splendor thorn valley meets time benefactors justin ages brutus guard appearance finally speaks providing characterization appearance film nimh brutus favorite animated characters characters including jenny mouse cecil bug surprises pop spoil remember mice sucked ventilation system attempting escape nimh killed gut wrenching shock revelation timothy brother martin turned dark side star talent contributes journey ralph macchio eric idle continues tradition lending voice talents awesome animated sagas providing depth feeling charming characters best dom deluise returns jeremy crow animation artful movie direct video absolutely par disney video sequels better dvd secret nimh satisfying sequel leaves small thread picked third film mystical amulet saved brisby mentioned missing',\n",
       "       'CD & Vinyl '], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values[1009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cb12e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lens = []\n",
    "for i in df.values:\n",
    "    lens.append(np.log(len(i[0])))\n",
    "plt.hist(lens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = df['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15400x43921 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 675525 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df['Review'])\n",
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15400, 43921)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15400, 43921)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, df['Class'])\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I've been ordering these for more than 1.5 years now. My pup likes to chew them and it keeps her busy for about an hour since she's small in size. The quality is fine and I have always received it in good condition. For the new pet owners, these pressed bone holds your pup attention for a while and are very helpful. Although buy the size suitable to your dog's breed.\" => Pet Supplies\n"
     ]
    }
   ],
   "source": [
    "logistic = logistic.fit(X_train_tfidf, df['Class'])\n",
    "\n",
    "\n",
    "#docs_new = [\"Quality of cards, money, houses,hotels are best. Houses and Hotels are made of wood. The dices are also of wood with numbers on them which are better than dices with dots. Good bank central bracket to keep money and cards which has separate sections for for everything. Tokens are heavy and good quality and made of brass which are better than plastic tokens. Overall a steal away at this price and this game is fun to play with friends and family. Flipkart delivered this product in 3 days.\"]\n",
    "#docs_new = [\"Henry Winkler stars in this remake of the classic tale of Scrooge.  This one is set in post-Depression era America and is oneof the best I've ever seen.  Winkler is equally at ease as a young man with a girlfriend or an old man with an attitude.  I watch this every Christmas and was delighted to discover it on DVD.  You'll love it!\"]\n",
    "docs_new = [\"I've been ordering these for more than 1.5 years now. My pup likes to chew them and it keeps her busy for about an hour since she's small in size. The quality is fine and I have always received it in good condition. For the new pet owners, these pressed bone holds your pup attention for a while and are very helpful. Although buy the size suitable to your dog's breed.\"]\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predictedMNB = logistic.predict(X_new_tfidf)\n",
    "#predicted\n",
    "for doc, category in zip(docs_new, predictedMNB):\n",
    "    print('%r => %s' % (doc, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', RandomForestClassifier(n_estimators=100, max_depth=None,\n",
    "    min_samples_split=10, random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82999999999999996"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = text_clf.fit(df['Review'], df['Class'])\n",
    "#docs_test = dfo.values\n",
    "predicted = text_clf.predict(dfo['Review'])\n",
    "np.mean(predicted == dfo['Class'])         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-185ab04058ba>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-185ab04058ba>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    alpha=1e-3, n_iter=5, random_state=)),\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, n_iter=5, random_state=)),\n",
    "])\n",
    "text_clf = text_clf.fit(df['Review'], df['Class'])\n",
    "predicted = text_clf.predict(dfo['Review'])\n",
    "np.mean(predicted == dfo['Class']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "   Cellphone Accessories       0.86      0.95      0.90       276\n",
      "              Automobile       0.93      0.84      0.88       317\n",
      "            digitalmusic       0.85      0.80      0.82       293\n",
      "    Clothing & Jewellery       0.82      0.91      0.86       265\n",
      "       patio&lawn&garden       0.92      0.79      0.85       306\n",
      "                  Beauty       0.77      0.88      0.82       306\n",
      "            Pet Supplies       0.90      0.85      0.88       320\n",
      "       music instruments       0.89      0.73      0.80       302\n",
      "             Movies & TV       0.84      0.81      0.83       286\n",
      "                  Health       0.89      0.84      0.86       315\n",
      "             CD & Vinyl        0.87      0.89      0.88       306\n",
      "             Electronics       0.88      0.90      0.89       295\n",
      "                 grocery       0.80      0.95      0.87       278\n",
      "        Apps for Android       0.87      0.72      0.79       315\n",
      "              videogames       0.85      0.96      0.90       294\n",
      "Tools & Home Improvement       0.85      0.76      0.80       300\n",
      "          HomeAndKitchen       0.90      0.85      0.87       313\n",
      "            ToysAndGames       0.89      0.97      0.93       310\n",
      "         Office Products       0.90      0.94      0.92       302\n",
      "    Amazon Instant Video       0.90      0.90      0.90       300\n",
      "                    baby       0.89      0.80      0.84       304\n",
      "       SportsAndOutdoors       0.79      0.98      0.88       297\n",
      "\n",
      "             avg / total       0.87      0.86      0.86      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(dfo['Class'], predicted,\n",
    "    target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[261,   1,   0,   1,   1,   0,   0,   0,   0,   0,   6,   1,   0,\n",
       "          1,   0,   1,   0,   0,   0,   1,   0,   2],\n",
       "       [  3, 266,   1,   0,   0,   7,   0,   2,   0,   0,   0,   0,   1,\n",
       "          0,   0,   8,   1,   1,   0,   1,   0,  26],\n",
       "       [  0,   0, 235,   2,   0,   6,   2,   2,   3,   8,   0,   2,   4,\n",
       "          4,  10,   1,   0,   0,   2,   6,   6,   0],\n",
       "       [  0,   0,   1, 241,   0,   2,   1,   0,   6,   0,   0,   2,   1,\n",
       "          4,   0,   1,   1,   0,   3,   0,   2,   0],\n",
       "       [  8,   0,   1,   0, 241,   0,   0,   0,   0,   0,  23,   1,   0,\n",
       "          0,   0,   0,   2,  25,   1,   4,   0,   0],\n",
       "       [  1,   0,   5,   0,   0, 269,   2,   6,   3,   3,   0,   6,   0,\n",
       "          5,   0,   0,   0,   1,   1,   4,   0,   0],\n",
       "       [  2,   0,   2,   4,   1,   9, 273,   3,   0,   0,   1,   0,   3,\n",
       "          3,   1,   6,   5,   0,   1,   2,   3,   1],\n",
       "       [  0,   6,   5,   1,   6,  27,   2, 220,   8,   2,   3,   5,   0,\n",
       "          0,   2,   1,   1,   4,   0,   8,   0,   1],\n",
       "       [  1,   1,   3,  10,   0,   4,   4,   2, 232,   2,   1,   3,   3,\n",
       "          4,   2,   0,   3,   0,  10,   0,   1,   0],\n",
       "       [  1,   1,   2,   1,   0,   3,   3,   2,   6, 265,   1,   2,   6,\n",
       "          6,   4,   3,   1,   0,   3,   0,   5,   0],\n",
       "       [ 15,   0,   0,   0,   9,   0,   0,   1,   0,   0, 272,   1,   0,\n",
       "          1,   3,   0,   2,   1,   1,   0,   0,   0],\n",
       "       [  0,   2,   1,   2,   0,  15,   0,   2,   3,   2,   0, 265,   0,\n",
       "          0,   1,   1,   0,   1,   0,   0,   0,   0],\n",
       "       [  1,   0,   2,   2,   0,   0,   0,   0,   1,   0,   0,   0, 264,\n",
       "          1,   0,   1,   1,   0,   2,   0,   3,   0],\n",
       "       [  3,   1,   4,  25,   0,   1,   5,   0,   4,   1,   1,   1,  10,\n",
       "        227,   9,   8,   5,   1,   4,   1,   2,   2],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   2,   3,   0,   0,   3,   0,\n",
       "          1, 282,   1,   1,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   2,   1,   0,   1,   0,   1,   0,   1,   2,   3,   8,\n",
       "          1,   2, 228,   3,   0,   2,   0,   0,  45],\n",
       "       [  1,   5,   0,   0,   0,   3,   2,   0,   1,   2,   0,   3,  19,\n",
       "          2,   2,   6, 266,   1,   0,   0,   0,   0],\n",
       "       [  1,   1,   0,   0,   4,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "          0,   0,   0,   0, 302,   0,   1,   0,   0],\n",
       "       [  2,   0,   0,   1,   1,   0,   1,   1,   0,   5,   0,   0,   1,\n",
       "          0,   0,   1,   1,   0, 283,   0,   5,   0],\n",
       "       [  0,   2,   7,   1,   0,   1,   5,   2,   1,   0,   1,   1,   1,\n",
       "          0,   1,   1,   1,   3,   0, 270,   2,   0],\n",
       "       [  4,   1,   7,   2,   0,   0,   3,   0,   4,   8,   0,   2,  10,\n",
       "          1,  12,   0,   3,   0,   3,   2, 242,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   1,   0,   0,   0,   0,   1,\n",
       "          0,   1,   1,   0,   0,   0,   1,   0, 291]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(dfo['Class'], predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67606060606060603"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf',  DecisionTreeClassifier(max_depth=200)),\n",
    "])\n",
    "text_clf = text_clf.fit(df['Review'], df['Class'])\n",
    "predicted = text_clf.predict(dfo['Review'])\n",
    "np.mean(predicted == dfo['Class']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76484848484848489"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf',  MLPClassifier(alpha=1)),\n",
    "])\n",
    "text_clf = text_clf.fit(df['Review'], df['Class'])\n",
    "predicted = text_clf.predict(dfo['Review'])\n",
    "np.mean(predicted == dfo['Class']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88969696969696965"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()\n",
    "#logistic.fit(df['Review'], df['Class'])\n",
    "logReg = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf',  LogisticRegression()),\n",
    "])\n",
    "logReg = logReg.fit(df['Review'], df['Class'])\n",
    "predicted = logReg.predict(dfo['Review'])\n",
    "np.mean(predicted == dfo['Class'])\n",
    "#below line not required \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data is not binary and pos_label is not specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-dd94c0647301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/arun/anaconda/lib/python3.5/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \"\"\"\n\u001b[1;32m    504\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 505\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/arun/anaconda/lib/python3.5/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    312\u001b[0m              \u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m              array_equal(classes, [1]))):\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data is not binary and pos_label is not specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mpos_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data is not binary and pos_label is not specified"
     ]
    }
   ],
   "source": [
    "#Purely for testing--- Delete later\n",
    "from sklearn import metrics\n",
    "#probs = model.predict_proba(X_test)\n",
    "#--predicted\n",
    "preds = predicted\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(dfo['Class'], preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've been ordering these for more than 1.5 years now. My pup likes to chew them and it keeps her busy for about an hour since she's small in size. The quality is fine and I have always received it in good condition. For the new pet owners, these pressed bone holds your pup attention for a while and are very helpful. Although buy the size suitable to your dog's breed.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"I've been ordering these for more than 1.5 years now. My pup likes to chew them and it keeps her busy for about an hour since she's small in size. The quality is fine and I have always received it in good condition. For the new pet owners, these pressed bone holds your pup attention for a while and are very helpful. Although buy the size suitable to your dog's breed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SVC()),\n",
    "])\n",
    "text_clf = text_clf.fit(df['Review'], df['Class'])\n",
    "predicted = text_clf.predict(dfo['Review'])\n",
    "np.mean(predicted == dfo['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
